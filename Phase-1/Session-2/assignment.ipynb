{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4 - Session 2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python361064biteva5conda7a77c4eb337b4f7ca8b1722eb0799895",
      "display_name": "Python 3.6.10 64-bit ('eva5': conda)"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Constructing the layers of the network:\n",
        "\n",
        "        # input: (1, 28, 28), output: (32, 28, 28), RF: 3x3\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "\n",
        "        # input: (32, 28, 28), output: (64, 28, 28), RF: 5x5\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "\n",
        "        # input: (64, 28, 28), output: (64, 14, 14), RF: 10x10\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # input: (64, 14, 14), output: (128, 14, 14), RF: 12x12\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "\n",
        "        # input: (128, 14, 14), output: (256, 14, 14), RF: 14x14\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "\n",
        "        # input: (256, 14, 14), output: (256, 7, 7), RF: 28x28\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # input: (256, 7, 7), output: (512, 5, 5), RF: 30x30\n",
        "        self.conv5 = nn.Conv2d(256, 512, 3)\n",
        "\n",
        "        # input: (512, 5, 5), output: (1024, 3, 3), RF: 32x32\n",
        "        self.conv6 = nn.Conv2d(512, 1024, 3)\n",
        "\n",
        "        # input: (1024, 3, 3), output: (10, 1, 1), RF: 34x34\n",
        "        self.conv7 = nn.Conv2d(1024, 10, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Defines operations to be carried out during forward prop.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): The input tensor to the model\n",
        "        \n",
        "        Returns:\n",
        "            Tensor: a tensor of size (B, 10)\n",
        "        \"\"\"\n",
        "        # initial shape of x: (B, 1, 28, 28)\n",
        "        # shape of x: (B, 64, 14, 14)\n",
        "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "\n",
        "        # shape of x: (B, 256, 7, 7)\n",
        "        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "\n",
        "        # shape of x: (B, 1024, 3, 3)\n",
        "        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "\n",
        "        # shape of x: (B, 10, 1, 1)\n",
        "        x = F.relu(self.conv7(x))\n",
        "\n",
        "        # shape of x: (B, 10)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xdydjYTZFyi3",
        "colab": {},
        "tags": []
      },
      "source": [
        "! pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "# checking if cuda is available for use\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "# if it is, setting the device to \"cuda\". else setting the device to be \"cpu\"\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "# instantiating the model, moving it to the device\n",
        "model = Net().to(device)\n",
        "\n",
        "# summarizing the model\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: torchsummary in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (1.5.1)\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 32, 28, 28]             320\n            Conv2d-2           [-1, 64, 28, 28]          18,496\n         MaxPool2d-3           [-1, 64, 14, 14]               0\n            Conv2d-4          [-1, 128, 14, 14]          73,856\n            Conv2d-5          [-1, 256, 14, 14]         295,168\n         MaxPool2d-6            [-1, 256, 7, 7]               0\n            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n            Conv2d-9             [-1, 10, 1, 1]          92,170\n================================================================\nTotal params: 6,379,786\nTrainable params: 6,379,786\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 1.51\nParams size (MB): 24.34\nEstimated Total Size (MB): 25.85\n----------------------------------------------------------------\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "# setting the seed for the random number generator used by pytorch\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# declaring batch size\n",
        "batch_size = 128\n",
        "# declaring additional arguments to be used if cuda is being used.\n",
        "# num_workers: number of subprocesses needed to load data to memory. if 0, main process loads \n",
        "# data to memory.\n",
        "# pin_memory: decides whether to use pinned memory or not. pinned memory is a non-paged staging area\n",
        "# for data transfers between CPU and GPU, and setting this argument to True can lead to speed up.\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "# creating the dataset\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        '../data', # the path to store the MNIST data\n",
        "        train=True, # defining that the data is training data\n",
        "        download=True, # defines that the data should be downloaded\n",
        "        transform=transforms.Compose([ # defining preprocessing operations that have to be performed on the dataset\n",
        "            transforms.ToTensor(), # first operation: Convert PIL image (downloaded image) to pytorch tensor\n",
        "            transforms.Normalize((0.1307,), (0.3081,)) # second operation: normalize the image with mean 0.1307 and std 0.3081\n",
        "        ]),\n",
        "    ),\n",
        "    batch_size=batch_size, # defining the batch size to be used\n",
        "    shuffle=True, # defining that the data should be shuffled prior to selecting batches\n",
        "    **kwargs # passing additional arguments\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        '../data', # the path to store the MNIST data\n",
        "        train=False,  # defining that the data is NOT training data\n",
        "        transform=transforms.Compose([ # defining preprocessing operations that have to be performed on the dataset\n",
        "            transforms.ToTensor(), # first operation: Convert PIL image (downloaded image) to pytorch tensor\n",
        "            transforms.Normalize((0.1307,), (0.3081,)) # second operation: normalize the image with mean 0.1307 and std 0.3081\n",
        "        ]),\n",
        "    ),\n",
        "    batch_size=batch_size, # defining the batch size to be used\n",
        "    shuffle=True, # defining that the data should be shuffled prior to selecting batches\n",
        "    **kwargs # passing additional arguments\n",
        ")\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    \"\"\"\n",
        "    Performs a single train step on the model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to train\n",
        "        device (str): The device the data should be moved to\n",
        "        train_loader (torch.utils.data.DataLoader): The data loader for the training data\n",
        "        optimizer (torch.optim.Optimizer): The optimizer to be used\n",
        "        epochs (int): The current epoch\n",
        "    \"\"\"\n",
        "\n",
        "    # setting the model in train mode\n",
        "    model.train()\n",
        "\n",
        "    # creating a progress bar\n",
        "    pbar = tqdm(train_loader)\n",
        "\n",
        "    # for each batch in the dataset,\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        # move the data to the device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # zero out the optimizer since pytorch accumulates the gradients on subsequent backward passes\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # perform forward pass\n",
        "        output = model(data)\n",
        "\n",
        "        # calculate the loss (loss function being used is negative log likelihood)\n",
        "        loss = F.nll_loss(output, target)\n",
        "\n",
        "        # calculate the gradients (mathematical gradients)\n",
        "        loss.backward()\n",
        "\n",
        "        # step the optimizer (updates the weights of the model)\n",
        "        optimizer.step()\n",
        "\n",
        "        # update progress bar\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    \"\"\"\n",
        "    Performs a single test step on the model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to train\n",
        "        device (str): The device the data should be moved to\n",
        "        test_loader (torch.utils.data.DataLoader): The data loader for the test data\n",
        "    \"\"\"\n",
        "\n",
        "    # setting the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # defining variables to store the test loss and the number \n",
        "    # of correctly classified images\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        " \n",
        "    # defining a \"no gradient calculation\" context\n",
        "    with torch.no_grad():\n",
        "        # for every batch in the dataset,\n",
        "        for data, target in test_loader:\n",
        "            # move the data to the device\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # perform the forward pass\n",
        "            output = model(data)\n",
        "            \n",
        "            # calculating test loss (summing up the losses in a batch instead of averaging them)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum')\n",
        "\n",
        "            # getting index of the element in the output tensor which has the largest value\n",
        "            # the index corresponds to the number the model thinks the image is. \n",
        "            # the output tensor has a shape of (B, 10), and pred will have the shape\n",
        "            # (B, 1)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            \n",
        "            # checking if the prediction was correct or not\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    # dividing the test loss by the size of the dataset\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    # printing results\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "# defining the optimizer that is to be used\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# running training loop for 1 epoch\n",
        "for epoch in range(1, 2):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "loss=0.47023406624794006 batch_id=468: 100%|██████████| 469/469 [00:19<00:00, 23.66it/s]\n\nTest set: Average loss: 0.5663, Accuracy: 8615/10000 (86%)\n\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5uk4EkHW6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}