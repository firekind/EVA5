{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599928053650",
   "display_name": "Python 3.7.9 64-bit ('eva5': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Collecting git+https://github.com/firekind/athena\n  Cloning https://github.com/firekind/athena to c:\\users\\shyam\\appdata\\local\\temp\\pip-req-build-uaf2tlx6\nRequirement already satisfied (use --upgrade to upgrade): athena==0.0.1 from git+https://github.com/firekind/athena in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages\nRequirement already satisfied: pkbar==0.4 in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from athena==0.0.1) (0.4)\nRequirement already satisfied: torchsummary in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from athena==0.0.1) (1.5.1)\nRequirement already satisfied: tqdm in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from athena==0.0.1) (4.48.2)\nRequirement already satisfied: matplotlib in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from athena==0.0.1) (3.3.1)\nRequirement already satisfied: numpy in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from pkbar==0.4->athena==0.0.1) (1.19.1)\nRequirement already satisfied: python-dateutil>=2.1 in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from matplotlib->athena==0.0.1) (2.8.1)\nRequirement already satisfied: cycler>=0.10 in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from matplotlib->athena==0.0.1) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from matplotlib->athena==0.0.1) (1.2.0)\nRequirement already satisfied: certifi>=2020.06.20 in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from matplotlib->athena==0.0.1) (2020.6.20)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from matplotlib->athena==0.0.1) (2.4.7)\nRequirement already satisfied: pillow>=6.2.0 in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from matplotlib->athena==0.0.1) (7.2.0)\nRequirement already satisfied: six>=1.5 in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from python-dateutil>=2.1->matplotlib->athena==0.0.1) (1.15.0)\nBuilding wheels for collected packages: athena\n  Building wheel for athena (setup.py): started\n  Building wheel for athena (setup.py): finished with status 'done'\n  Created wheel for athena: filename=athena-0.0.1-py3-none-any.whl size=17745 sha256=a3e9df1b9448169019008175e8a49592c27d712b31cdf34f93d4b74915747d88\n  Stored in directory: C:\\Users\\shyam\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-opm_xbn0\\wheels\\c2\\36\\ea\\fe5a118d0035f6f760fc49471824263f1b0e611bcba3555bde\nSuccessfully built athena\n"
    }
   ],
   "source": [
    "! pip install git+https://github.com/firekind/athena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "import torchvision as tv\n",
    "\n",
    "from athena import ClassificationSolver, Experiment, datasets\n",
    "from athena.models import Cifar10V1\n",
    "from athena.layers import DepthwiseConv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 128 if torch.cuda.is_available() else 64\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Files already downloaded and verified\nFiles already downloaded and verified\n"
    }
   ],
   "source": [
    "train_loader = datasets.cifar10(download=True, batch_size=batch_size, use_default_transforms=True)\n",
    "test_loader = datasets.cifar10(train=False, download=True, batch_size=batch_size, use_default_transforms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cifar10V1().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.008, momentum=0.95)\n",
    "exp = Experiment(\n",
    "    name=\"Cifar 10\",\n",
    "    model=model,\n",
    "    solver_cls=ClassificationSolver,\n",
    "    train_args=dict(\n",
    "        epochs=epochs,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[1m\u001b[92m=> Running experiment: Cifar 10\u001b[0m\n\u001b[1m\u001b[93mWarning:\u001b[0m Loss function not specified. Using nll loss.\nEpoch: 1 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 1.6412 - accuracy: 31.8140\nTest set: Average loss: 3.1699, Accuracy: 1672/10000 (16.72%)\n\nEpoch: 2 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 1.0992 - accuracy: 50.0680\nTest set: Average loss: 2.7842, Accuracy: 2560/10000 (25.60%)\n\nEpoch: 3 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.9770 - accuracy: 58.6580\nTest set: Average loss: 2.1029, Accuracy: 3441/10000 (34.41%)\n\nEpoch: 4 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.9364 - accuracy: 64.2000\nTest set: Average loss: 2.0909, Accuracy: 3498/10000 (34.98%)\n\nEpoch: 5 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.8696 - accuracy: 67.8320\nTest set: Average loss: 2.3855, Accuracy: 3665/10000 (36.65%)\n\nEpoch: 6 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.7357 - accuracy: 70.8860\nTest set: Average loss: 1.5078, Accuracy: 5153/10000 (51.53%)\n\nEpoch: 7 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.6762 - accuracy: 72.8580\nTest set: Average loss: 1.3997, Accuracy: 5443/10000 (54.43%)\n\nEpoch: 8 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.7799 - accuracy: 74.4240\nTest set: Average loss: 1.5171, Accuracy: 5347/10000 (53.47%)\n\nEpoch: 9 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.7043 - accuracy: 75.9840\nTest set: Average loss: 1.4554, Accuracy: 5600/10000 (56.00%)\n\nEpoch: 10 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.7199 - accuracy: 76.9320\nTest set: Average loss: 0.8925, Accuracy: 6933/10000 (69.33%)\n\nEpoch: 11 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.6291 - accuracy: 77.8880\nTest set: Average loss: 1.0155, Accuracy: 6678/10000 (66.78%)\n\nEpoch: 12 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.8406 - accuracy: 78.6680\nTest set: Average loss: 1.1342, Accuracy: 6317/10000 (63.17%)\n\nEpoch: 13 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.5409 - accuracy: 79.7620\nTest set: Average loss: 0.7418, Accuracy: 7413/10000 (74.13%)\n\nEpoch: 14 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.6684 - accuracy: 80.4020\nTest set: Average loss: 1.0957, Accuracy: 6548/10000 (65.48%)\n\nEpoch: 15 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.6804 - accuracy: 81.2220\nTest set: Average loss: 0.8018, Accuracy: 7206/10000 (72.06%)\n\nEpoch: 16 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.4269 - accuracy: 81.6420\nTest set: Average loss: 0.7436, Accuracy: 7425/10000 (74.25%)\n\nEpoch: 17 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.5256 - accuracy: 82.3020\nTest set: Average loss: 0.8985, Accuracy: 7109/10000 (71.09%)\n\nEpoch: 18 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.5734 - accuracy: 82.8180\nTest set: Average loss: 0.7726, Accuracy: 7391/10000 (73.91%)\n\nEpoch: 19 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.4679 - accuracy: 83.2740\nTest set: Average loss: 0.9886, Accuracy: 6765/10000 (67.65%)\n\nEpoch: 20 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.4632 - accuracy: 83.8920\nTest set: Average loss: 0.7828, Accuracy: 7338/10000 (73.38%)\n\nEpoch: 21 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.3390 - accuracy: 84.1140\nTest set: Average loss: 0.6856, Accuracy: 7675/10000 (76.75%)\n\nEpoch: 22 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.3551 - accuracy: 84.6140\nTest set: Average loss: 0.6461, Accuracy: 7789/10000 (77.89%)\n\nEpoch: 23 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.4462 - accuracy: 85.0900\nTest set: Average loss: 0.8353, Accuracy: 7328/10000 (73.28%)\n\nEpoch: 24 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.2417 - accuracy: 85.1340\nTest set: Average loss: 0.6105, Accuracy: 7907/10000 (79.07%)\n\nEpoch: 25 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.3039 - accuracy: 85.8440\nTest set: Average loss: 0.6705, Accuracy: 7763/10000 (77.63%)\n\nEpoch: 26 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.3280 - accuracy: 85.7700\nTest set: Average loss: 0.6391, Accuracy: 7820/10000 (78.20%)\n\nEpoch: 27 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.6028 - accuracy: 86.1620\nTest set: Average loss: 0.6987, Accuracy: 7693/10000 (76.93%)\n\nEpoch: 28 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.3161 - accuracy: 86.3360\nTest set: Average loss: 0.7795, Accuracy: 7521/10000 (75.21%)\n\nEpoch: 29 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.4577 - accuracy: 86.8060\nTest set: Average loss: 0.7219, Accuracy: 7682/10000 (76.82%)\n\nEpoch: 30 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.5051 - accuracy: 87.1260\nTest set: Average loss: 0.6683, Accuracy: 7846/10000 (78.46%)\n\nEpoch: 31 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.4053 - accuracy: 87.2780\nTest set: Average loss: 0.5755, Accuracy: 8060/10000 (80.60%)\n\nEpoch: 32 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.3532 - accuracy: 87.5920\nTest set: Average loss: 0.6194, Accuracy: 7966/10000 (79.66%)\n\nEpoch: 33 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.2746 - accuracy: 87.6060\nTest set: Average loss: 0.6487, Accuracy: 7885/10000 (78.85%)\n\nEpoch: 34 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.2657 - accuracy: 88.0340\nTest set: Average loss: 0.7176, Accuracy: 7733/10000 (77.33%)\n\nEpoch: 35 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.3952 - accuracy: 88.0620\nTest set: Average loss: 0.7379, Accuracy: 7759/10000 (77.59%)\n\nEpoch: 36 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.4567 - accuracy: 88.4740\nTest set: Average loss: 0.6579, Accuracy: 7876/10000 (78.76%)\n\nEpoch: 37 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.5222 - accuracy: 88.5620\nTest set: Average loss: 0.5867, Accuracy: 8154/10000 (81.54%)\n\nEpoch: 38 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.1925 - accuracy: 88.9620\nTest set: Average loss: 0.7153, Accuracy: 7815/10000 (78.15%)\n\nEpoch: 39 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.3681 - accuracy: 89.0880\nTest set: Average loss: 0.6337, Accuracy: 8065/10000 (80.65%)\n\nEpoch: 40 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.3940 - accuracy: 89.0100\nTest set: Average loss: 0.5403, Accuracy: 8184/10000 (81.84%)\n\nEpoch: 41 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.2367 - accuracy: 89.6020\nTest set: Average loss: 0.5370, Accuracy: 8273/10000 (82.73%)\n\nEpoch: 42 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.2091 - accuracy: 89.5160\nTest set: Average loss: 0.6672, Accuracy: 7929/10000 (79.29%)\n\nEpoch: 43 / 50\n391/391 [==============================] - 39s 99ms/step - loss: 0.4047 - accuracy: 89.4600\nTest set: Average loss: 0.6095, Accuracy: 8143/10000 (81.43%)\n\nEpoch: 44 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.2985 - accuracy: 89.9760\nTest set: Average loss: 0.6625, Accuracy: 7976/10000 (79.76%)\n\nEpoch: 45 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.4089 - accuracy: 90.2380\nTest set: Average loss: 0.5928, Accuracy: 8171/10000 (81.71%)\n\nEpoch: 46 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.2184 - accuracy: 90.2660\nTest set: Average loss: 0.5807, Accuracy: 8168/10000 (81.68%)\n\nEpoch: 47 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.2928 - accuracy: 90.4080\nTest set: Average loss: 0.6067, Accuracy: 8072/10000 (80.72%)\n\nEpoch: 48 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.4077 - accuracy: 90.4120\nTest set: Average loss: 0.5109, Accuracy: 8363/10000 (83.63%)\n\nEpoch: 49 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.2714 - accuracy: 90.7680\nTest set: Average loss: 0.6770, Accuracy: 7949/10000 (79.49%)\n\nEpoch: 50 / 50\n391/391 [==============================] - 38s 98ms/step - loss: 0.2823 - accuracy: 91.0240\nTest set: Average loss: 0.6403, Accuracy: 8039/10000 (80.39%)\n\n"
    }
   ],
   "source": [
    "exp.run()"
   ]
  }
 ]
}