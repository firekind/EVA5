{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599928053650",
   "display_name": "Python 3.7.9 64-bit ('eva5': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing developed package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Collecting git+https://github.com/firekind/athena\n  Cloning https://github.com/firekind/athena to c:\\users\\shyam\\appdata\\local\\temp\\pip-req-build-uaf2tlx6\nRequirement already satisfied (use --upgrade to upgrade): athena==0.0.1 from git+https://github.com/firekind/athena in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages\nRequirement already satisfied: pkbar==0.4 in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from athena==0.0.1) (0.4)\nRequirement already satisfied: torchsummary in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from athena==0.0.1) (1.5.1)\nRequirement already satisfied: tqdm in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from athena==0.0.1) (4.48.2)\nRequirement already satisfied: matplotlib in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from athena==0.0.1) (3.3.1)\nRequirement already satisfied: numpy in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from pkbar==0.4->athena==0.0.1) (1.19.1)\nRequirement already satisfied: python-dateutil>=2.1 in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from matplotlib->athena==0.0.1) (2.8.1)\nRequirement already satisfied: cycler>=0.10 in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from matplotlib->athena==0.0.1) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from matplotlib->athena==0.0.1) (1.2.0)\nRequirement already satisfied: certifi>=2020.06.20 in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from matplotlib->athena==0.0.1) (2020.6.20)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from matplotlib->athena==0.0.1) (2.4.7)\nRequirement already satisfied: pillow>=6.2.0 in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from matplotlib->athena==0.0.1) (7.2.0)\nRequirement already satisfied: six>=1.5 in d:\\users\\shyam\\scoop\\apps\\miniconda3\\current\\envs\\eva5\\lib\\site-packages (from python-dateutil>=2.1->matplotlib->athena==0.0.1) (1.15.0)\nBuilding wheels for collected packages: athena\n  Building wheel for athena (setup.py): started\n  Building wheel for athena (setup.py): finished with status 'done'\n  Created wheel for athena: filename=athena-0.0.1-py3-none-any.whl size=17745 sha256=a3e9df1b9448169019008175e8a49592c27d712b31cdf34f93d4b74915747d88\n  Stored in directory: C:\\Users\\shyam\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-opm_xbn0\\wheels\\c2\\36\\ea\\fe5a118d0035f6f760fc49471824263f1b0e611bcba3555bde\nSuccessfully built athena\n"
    }
   ],
   "source": [
    "! pip install git+https://github.com/firekind/athena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "import torchvision as tv\n",
    "\n",
    "from athena import ClassificationSolver, Experiment, datasets\n",
    "from athena.models import Cifar10V1\n",
    "from athena.layers import DepthwiseConv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters and loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 128 if torch.cuda.is_available() else 64\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transforms used are:\n",
    "\n",
    "    - ToTensor\n",
    "    - Normalize to mean and std of (0.5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Files already downloaded and verified\nFiles already downloaded and verified\n"
    }
   ],
   "source": [
    "train_loader = datasets.cifar10(download=True, batch_size=batch_size, use_default_transforms=True)\n",
    "test_loader = datasets.cifar10(train=False, download=True, batch_size=batch_size, use_default_transforms=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Experiment and running it\n",
    "\n",
    "The model was trained for 50 epochs. Despite the required accuracy being achieved (highest accuracy of 83.63% reached at epoch 48), the model shows heavy signs of overfitting.\n",
    "\n",
    "The link to the file containing the model in the package: [Model source code](https://github.com/firekind/athena/blob/master/athena/models/cifar10_v1.py)\n",
    "and [here's the link to the package documentation](https://firekind.github.io/athena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cifar10V1().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.008, momentum=0.95)\n",
    "exp = Experiment(\n",
    "    name=\"Cifar 10\",\n",
    "    model=model,\n",
    "    solver_cls=ClassificationSolver,\n",
    "    train_args=dict(\n",
    "        epochs=epochs,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[1m\u001b[92m=> Running experiment: Cifar 10\u001b[0m\n\u001b[1m\u001b[93mWarning:\u001b[0m Loss function not specified. Using nll loss.\nEpoch: 1 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 1.6412 - accuracy: 31.8140\nTest set: Average loss: 3.1699, Accuracy: 1672/10000 (16.72%)\n\nEpoch: 2 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 1.0992 - accuracy: 50.0680\nTest set: Average loss: 2.7842, Accuracy: 2560/10000 (25.60%)\n\nEpoch: 3 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.9770 - accuracy: 58.6580\nTest set: Average loss: 2.1029, Accuracy: 3441/10000 (34.41%)\n\nEpoch: 4 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.9364 - accuracy: 64.2000\nTest set: Average loss: 2.0909, Accuracy: 3498/10000 (34.98%)\n\nEpoch: 5 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.8696 - accuracy: 67.8320\nTest set: Average loss: 2.3855, Accuracy: 3665/10000 (36.65%)\n\nEpoch: 6 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.7357 - accuracy: 70.8860\nTest set: Average loss: 1.5078, Accuracy: 5153/10000 (51.53%)\n\nEpoch: 7 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.6762 - accuracy: 72.8580\nTest set: Average loss: 1.3997, Accuracy: 5443/10000 (54.43%)\n\nEpoch: 8 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.7799 - accuracy: 74.4240\nTest set: Average loss: 1.5171, Accuracy: 5347/10000 (53.47%)\n\nEpoch: 9 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.7043 - accuracy: 75.9840\nTest set: Average loss: 1.4554, Accuracy: 5600/10000 (56.00%)\n\nEpoch: 10 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.7199 - accuracy: 76.9320\nTest set: Average loss: 0.8925, Accuracy: 6933/10000 (69.33%)\n\nEpoch: 11 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.6291 - accuracy: 77.8880\nTest set: Average loss: 1.0155, Accuracy: 6678/10000 (66.78%)\n\nEpoch: 12 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.8406 - accuracy: 78.6680\nTest set: Average loss: 1.1342, Accuracy: 6317/10000 (63.17%)\n\nEpoch: 13 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.5409 - accuracy: 79.7620\nTest set: Average loss: 0.7418, Accuracy: 7413/10000 (74.13%)\n\nEpoch: 14 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.6684 - accuracy: 80.4020\nTest set: Average loss: 1.0957, Accuracy: 6548/10000 (65.48%)\n\nEpoch: 15 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.6804 - accuracy: 81.2220\nTest set: Average loss: 0.8018, Accuracy: 7206/10000 (72.06%)\n\nEpoch: 16 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.4269 - accuracy: 81.6420\nTest set: Average loss: 0.7436, Accuracy: 7425/10000 (74.25%)\n\nEpoch: 17 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.5256 - accuracy: 82.3020\nTest set: Average loss: 0.8985, Accuracy: 7109/10000 (71.09%)\n\nEpoch: 18 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.5734 - accuracy: 82.8180\nTest set: Average loss: 0.7726, Accuracy: 7391/10000 (73.91%)\n\nEpoch: 19 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.4679 - accuracy: 83.2740\nTest set: Average loss: 0.9886, Accuracy: 6765/10000 (67.65%)\n\nEpoch: 20 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.4632 - accuracy: 83.8920\nTest set: Average loss: 0.7828, Accuracy: 7338/10000 (73.38%)\n\nEpoch: 21 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.3390 - accuracy: 84.1140\nTest set: Average loss: 0.6856, Accuracy: 7675/10000 (76.75%)\n\nEpoch: 22 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.3551 - accuracy: 84.6140\nTest set: Average loss: 0.6461, Accuracy: 7789/10000 (77.89%)\n\nEpoch: 23 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.4462 - accuracy: 85.0900\nTest set: Average loss: 0.8353, Accuracy: 7328/10000 (73.28%)\n\nEpoch: 24 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.2417 - accuracy: 85.1340\nTest set: Average loss: 0.6105, Accuracy: 7907/10000 (79.07%)\n\nEpoch: 25 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.3039 - accuracy: 85.8440\nTest set: Average loss: 0.6705, Accuracy: 7763/10000 (77.63%)\n\nEpoch: 26 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.3280 - accuracy: 85.7700\nTest set: Average loss: 0.6391, Accuracy: 7820/10000 (78.20%)\n\nEpoch: 27 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.6028 - accuracy: 86.1620\nTest set: Average loss: 0.6987, Accuracy: 7693/10000 (76.93%)\n\nEpoch: 28 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.3161 - accuracy: 86.3360\nTest set: Average loss: 0.7795, Accuracy: 7521/10000 (75.21%)\n\nEpoch: 29 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.4577 - accuracy: 86.8060\nTest set: Average loss: 0.7219, Accuracy: 7682/10000 (76.82%)\n\nEpoch: 30 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.5051 - accuracy: 87.1260\nTest set: Average loss: 0.6683, Accuracy: 7846/10000 (78.46%)\n\nEpoch: 31 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.4053 - accuracy: 87.2780\nTest set: Average loss: 0.5755, Accuracy: 8060/10000 (80.60%)\n\nEpoch: 32 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.3532 - accuracy: 87.5920\nTest set: Average loss: 0.6194, Accuracy: 7966/10000 (79.66%)\n\nEpoch: 33 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.2746 - accuracy: 87.6060\nTest set: Average loss: 0.6487, Accuracy: 7885/10000 (78.85%)\n\nEpoch: 34 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.2657 - accuracy: 88.0340\nTest set: Average loss: 0.7176, Accuracy: 7733/10000 (77.33%)\n\nEpoch: 35 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.3952 - accuracy: 88.0620\nTest set: Average loss: 0.7379, Accuracy: 7759/10000 (77.59%)\n\nEpoch: 36 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.4567 - accuracy: 88.4740\nTest set: Average loss: 0.6579, Accuracy: 7876/10000 (78.76%)\n\nEpoch: 37 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.5222 - accuracy: 88.5620\nTest set: Average loss: 0.5867, Accuracy: 8154/10000 (81.54%)\n\nEpoch: 38 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.1925 - accuracy: 88.9620\nTest set: Average loss: 0.7153, Accuracy: 7815/10000 (78.15%)\n\nEpoch: 39 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.3681 - accuracy: 89.0880\nTest set: Average loss: 0.6337, Accuracy: 8065/10000 (80.65%)\n\nEpoch: 40 / 50\n391/391 [==============================] - 38s 96ms/step - loss: 0.3940 - accuracy: 89.0100\nTest set: Average loss: 0.5403, Accuracy: 8184/10000 (81.84%)\n\nEpoch: 41 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.2367 - accuracy: 89.6020\nTest set: Average loss: 0.5370, Accuracy: 8273/10000 (82.73%)\n\nEpoch: 42 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.2091 - accuracy: 89.5160\nTest set: Average loss: 0.6672, Accuracy: 7929/10000 (79.29%)\n\nEpoch: 43 / 50\n391/391 [==============================] - 39s 99ms/step - loss: 0.4047 - accuracy: 89.4600\nTest set: Average loss: 0.6095, Accuracy: 8143/10000 (81.43%)\n\nEpoch: 44 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.2985 - accuracy: 89.9760\nTest set: Average loss: 0.6625, Accuracy: 7976/10000 (79.76%)\n\nEpoch: 45 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.4089 - accuracy: 90.2380\nTest set: Average loss: 0.5928, Accuracy: 8171/10000 (81.71%)\n\nEpoch: 46 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.2184 - accuracy: 90.2660\nTest set: Average loss: 0.5807, Accuracy: 8168/10000 (81.68%)\n\nEpoch: 47 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.2928 - accuracy: 90.4080\nTest set: Average loss: 0.6067, Accuracy: 8072/10000 (80.72%)\n\nEpoch: 48 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.4077 - accuracy: 90.4120\nTest set: Average loss: 0.5109, Accuracy: 8363/10000 (83.63%)\n\nEpoch: 49 / 50\n391/391 [==============================] - 38s 97ms/step - loss: 0.2714 - accuracy: 90.7680\nTest set: Average loss: 0.6770, Accuracy: 7949/10000 (79.49%)\n\nEpoch: 50 / 50\n391/391 [==============================] - 38s 98ms/step - loss: 0.2823 - accuracy: 91.0240\nTest set: Average loss: 0.6403, Accuracy: 8039/10000 (80.39%)\n\n"
    }
   ],
   "source": [
    "exp.run()"
   ]
  }
 ]
}